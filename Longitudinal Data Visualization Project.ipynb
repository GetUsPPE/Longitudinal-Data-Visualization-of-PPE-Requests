{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal Data Visualization Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    \"./getusppe-93fe2669c4a3.json\",\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "client = bigquery.Client(\n",
    "    credentials=credentials,\n",
    "    project=credentials.project_id,\n",
    ")\n",
    "QUERY = ('select * from gateway.request limit 10')\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"SELECT * FROM gateway.request\"\n",
    "bq_df = client.query(query_string).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "display(bq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename parameters\n",
    "requestors_filename = \"requestor-Grid view.csv\"\n",
    "requestors_timestamped_filename = \"data-1591226924897.csv\"\n",
    "output_new_timestamps_filename = \"requestors_new_timestamps.csv\"\n",
    "output_sorted_binary_filename = \"requestors_new_timestamps_sorted_binary.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file with requestors\n",
    "reqs = pd.io.parsers.read_csv(requestors_filename, low_memory=False)\n",
    "reqs_ts = pd.io.parsers.read_csv(requestors_timestamped_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match new timestamps from Airtable database with GCP BigQuery, append to list\n",
    "new_timestamps = []\n",
    "for index, row in reqs.iterrows():\n",
    "    # Filter out by state/city first, then run extract\n",
    "    df = bq_df[(bq_df['requestkey'] == row['requestKey'])]\n",
    "    if len(df.index) == 1:\n",
    "        new_timestamps.append(df.iloc[0]['datecreated'])\n",
    "    else:\n",
    "        new_timestamps.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Match new timestamps from Airtable database, append to list\n",
    "# new_timestamps = []\n",
    "# for index, row in reqs.iterrows():\n",
    "#     # Filter out by state/city first, then run extract\n",
    "#     df = reqs_ts[(reqs_ts['requestkey'] == row['requestKey'])]\n",
    "#     if len(df.index) == 1:\n",
    "#         new_timestamps.append(df.iloc[0]['datecreated'])\n",
    "#     else:\n",
    "#         new_timestamps.append('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for the fixed timestamps in the original database\n",
    "reqs['newDateCreated'] = new_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export with new timestamps\n",
    "reqs.to_csv(output_new_timestamps_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime objects\n",
    "reqs['newDateCreated'] = pd.to_datetime(reqs['newDateCreated'], errors='coerce', format=\"%Y-%m-%d %H:%M:%S\", utc=True)\n",
    "\n",
    "# Sort requests by date, ascending\n",
    "sorted_reqs = reqs.sort_values(by='newDateCreated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "sorted_reqs = sorted_reqs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary yes/no columns for requests by type (>0 requested, or == -1 (binary yes/no))\n",
    "sorted_reqs['requestedRespirators'] = sorted_reqs.apply(lambda row : row['respirators'] > 0 or row['respirators'] < 0, axis=1)\n",
    "sorted_reqs['requestedSurgicalMasks'] = sorted_reqs.apply(lambda row : row['surgicalMasks'] > 0 or row['surgicalMasks'] < 0, axis=1)\n",
    "sorted_reqs['requestedFaceShields'] = sorted_reqs.apply(lambda row : row['faceShields'] > 0 or row['faceShields'] < 0, axis=1)\n",
    "sorted_reqs['requestedSafetyGoggles'] = sorted_reqs.apply(lambda row : row['safetyGoggles'] > 0 or row['safetyGoggles'] < 0, axis=1)\n",
    "sorted_reqs['requestedSafetyGlasses'] = sorted_reqs.apply(lambda row : row['safetyGlasses'] > 0 or row['safetyGlasses'] < 0, axis=1)\n",
    "sorted_reqs['requestedDisposableBooties'] = sorted_reqs.apply(lambda row : row['disposableBooties'] > 0 or row['disposableBooties'] < 0, axis=1)\n",
    "sorted_reqs['requestedNitrileGloves'] = sorted_reqs.apply(lambda row : row['nitrileGloves'] > 0 or row['nitrileGloves'] < 0, axis=1)\n",
    "sorted_reqs['requestedGowns'] = sorted_reqs.apply(lambda row : row['gowns'] > 0 or row['gowns'] > 0, axis=1)\n",
    "sorted_reqs['requestedCoveralls'] = sorted_reqs.apply(lambda row : row['coveralls'] > 0 or row['coveralls'] < 0, axis=1)\n",
    "sorted_reqs['requestedSurgicalCaps'] = sorted_reqs.apply(lambda row : row['surgicalCaps'] > 0 or row['surgicalCaps'] < 0, axis=1)\n",
    "sorted_reqs['requestedHandSanitizer'] = sorted_reqs.apply(lambda row : row['handSanitizer'] > 0 or row['handSanitizer'] < 0, axis=1)\n",
    "sorted_reqs['requestedDisinfectingWipes'] = sorted_reqs.apply(lambda row : row['disinfectingWipes'] > 0 or row['disinfectingWipes'] < 0, axis=1)\n",
    "sorted_reqs['requestedThermometers'] = sorted_reqs.apply(lambda row : row['thermometers'] > 0 or row['thermometers'] < 0, axis=1)\n",
    "sorted_reqs['requestedHandmadeMasks'] = sorted_reqs.apply(lambda row : row['handmadeMasks'] > 0 or row['handmadeMasks'] < 0, axis=1)\n",
    "sorted_reqs['requestedPrintedFaceShields'] = sorted_reqs.apply(lambda row : row['printedFaceShields'] > 0 or row['printedFaceShields'] < 0, axis=1)\n",
    "sorted_reqs['requestedGownsOrCoveralls'] = sorted_reqs.apply(lambda row : row['gowns'] > 0 or row['gowns'] > 0 or row['coveralls'] > 0 or row['coveralls'] < 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file\n",
    "sorted_reqs.to_csv(output_sorted_binary_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and end date from dataset\n",
    "start_date = min(sorted_reqs['newDateCreated'].dt.date)\n",
    "end_date = max(sorted_reqs['newDateCreated'].dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries slicing by day\n",
    "idx = pd.date_range(start_date, periods=(end_date - start_date).days + 1, freq='D')\n",
    "df_sliced_day = idx.to_frame(index=False, name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for each type of PPE\n",
    "types = ['respirators', 'surgicalMasks', 'faceShields', 'safetyGoggles', 'safetyGlasses', 'disposableBooties', 'nitrileGloves', 'gowns', 'coveralls', 'surgicalCaps', 'handSanitizer', 'disinfectingWipes', 'thermometers', 'handmadeMasks', 'printedFaceShields', 'gownsOrCoveralls']\n",
    "for t in types:\n",
    "    df_sliced_day[t] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this method to convert from timestamp -> datetime object\n",
    "idx[0].to_pydatetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tally up totals\n",
    "# types_reqs = ['requested' + t[0].upper() + t[1:] for t in types]\n",
    "# for index, row in df_sliced_day.iterrows():\n",
    "#     for i in range(len(types)):\n",
    "#         # all matching dates\n",
    "#         total = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() == row['date'].to_pydatetime())]\n",
    "#         # all matching dates and item was requested is True\n",
    "#         items = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() == row['date'].to_pydatetime()) & (sorted_reqs[types_reqs[i]])]\n",
    "# #         print(temp)\n",
    "\n",
    "#         # Normalize based on each date's total number of requests\n",
    "#         if len(total.index) == 0:  # don't divide by 0\n",
    "#             df_sliced_day.at[index, types[i]] = 0\n",
    "#         else:\n",
    "#             df_sliced_day.at[index, types[i]] = len(total.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove timezone to avoid error comparing naive datetime objects to timezone-aware ones\n",
    "sorted_reqs['newDateCreated'] = sorted_reqs['newDateCreated'].dt.tz_convert(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tally up binary yes's/no's for each day\n",
    "types_reqs = ['requested' + t[0].upper() + t[1:] for t in types]\n",
    "for index, row in df_sliced_day.iterrows():\n",
    "    for i in range(len(types)):\n",
    "        # all matching dates\n",
    "        total = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() == row['date'].to_pydatetime())]\n",
    "        # all matching dates and item was requested is True\n",
    "        items = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() == row['date'].to_pydatetime()) & (sorted_reqs[types_reqs[i]])]\n",
    "#         print(temp)\n",
    "\n",
    "        # Normalize based on each date's total number of requests\n",
    "        if len(total.index) == 0:  # don't divide by 0\n",
    "            df_sliced_day.at[index, types[i]] = 0\n",
    "        else:\n",
    "            df_sliced_day.at[index, types[i]] = len(items.index) * 1.0 / len(total.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sliced_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [x.date() for x in list(df_sliced_day['date'])]\n",
    "dates_as_nums = [x.toordinal() for x in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of requests by day\n",
    "# plt.clf()\n",
    "\n",
    "# dates = [x.date() for x in list(df_sliced_day['date'])]\n",
    "# dates_as_nums = [x.toordinal() for x in dates]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15,15))\n",
    "# for t in ['respirators']:\n",
    "#     coef = np.polyfit(dates_as_nums,df_sliced_day[t],1)\n",
    "#     poly1d_fn = np.poly1d(coef)\n",
    "#     ax.plot(dates, df_sliced_day[t])\n",
    "#     ax.plot(dates_as_nums, poly1d_fn(dates_as_nums), label=\"Total number of requests\")\n",
    "# ax.legend()\n",
    "\n",
    "# # ax.set_xticks(np.arange(len(dates)))\n",
    "# # ax.set_xticklabels(dates)\n",
    "# plt.title('Total PPE Requests, Sliced by Day')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Number of Requests')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "# From: https://stackoverflow.com/questions/893657/how-do-i-calculate-r-squared-using-python-and-numpy\n",
    "def polyfit(x, y, degree):\n",
    "    results = {}\n",
    "\n",
    "    coeffs = np.polyfit(x, y, degree)\n",
    "\n",
    "     # Polynomial Coefficients\n",
    "    results['polynomial'] = coeffs.tolist()\n",
    "\n",
    "    # r-squared\n",
    "    p = np.poly1d(coeffs)\n",
    "    # fit values, and mean\n",
    "    yhat = p(x)                         # or [p(z) for z in x]\n",
    "    ybar = np.sum(y)/len(y)          # or sum(y)/len(y)\n",
    "    ssreg = np.sum((yhat-ybar)**2)   # or sum([ (yihat - ybar)**2 for yihat in yhat])\n",
    "    sstot = np.sum((y - ybar)**2)    # or sum([ (yi - ybar)**2 for yi in y])\n",
    "    results['rsquared'] = ssreg / sstot\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sliced by day\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "dates = [x.date() for x in list(df_sliced_day['date'])]\n",
    "dates_as_nums = [x.toordinal() for x in dates]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "for t in types:\n",
    "    results = polyfit(dates_as_nums,df_sliced_day[t],1)\n",
    "    coef = results['polynomial']\n",
    "    poly1d_fn = np.poly1d(coef)\n",
    "    ax.scatter(dates, df_sliced_day[t], label=t)\n",
    "    ax.plot(dates_as_nums, poly1d_fn(dates_as_nums), label=(t + \" | R^2 = \" + str(round(results['rsquared'],3))))\n",
    "ax.legend()\n",
    "\n",
    "# ax.set_xticks(np.arange(len(dates)))\n",
    "# ax.set_xticklabels(dates)\n",
    "plt.title('Type of PPE Requested Over Time, Sliced by Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Number of Requests (Fraction of Requests Per Day By Type)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot only respirators, face shields, and gowns\n",
    "plt.clf()\n",
    "\n",
    "dates = [x.date() for x in list(df_sliced_day['date'])]\n",
    "dates_as_nums = [x.toordinal() for x in dates]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "for t in ['respirators', 'faceShields', 'gownsOrCoveralls']:\n",
    "    coef = np.polyfit(dates_as_nums,df_sliced_day[t],1)\n",
    "    poly1d_fn = np.poly1d(coef)\n",
    "    ax.scatter(dates, df_sliced_day[t], label=t)\n",
    "    ax.plot(dates_as_nums, poly1d_fn(dates_as_nums), label=t)\n",
    "ax.legend()\n",
    "\n",
    "# ax.set_xticks(np.arange(len(dates)))\n",
    "# ax.set_xticklabels(dates)\n",
    "plt.title('Type of PPE Requested Over Time, Sliced by Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Number of Requests (Fraction of Requests Per Day By Type)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot each type on own individual plot\n",
    "plt.clf()\n",
    "\n",
    "dates = [x.date() for x in list(df_sliced_day['date'])]\n",
    "dates_as_nums = [x.toordinal() for x in dates]\n",
    "\n",
    "\n",
    "for t in types:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    coef = np.polyfit(dates_as_nums,df_sliced_day[t],1)\n",
    "    poly1d_fn = np.poly1d(coef)\n",
    "    ax.scatter(dates, df_sliced_day[t], label=t)\n",
    "    ax.plot(dates_as_nums, poly1d_fn(dates_as_nums), label=t)\n",
    "    ax.legend()\n",
    "    plt.title('Type of PPE Requested Over Time, Sliced by Day')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Number of Requests (Fraction of Requests Per Day By Type)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timeseries slicing by week\n",
    "idx = pd.date_range(start_date, periods=((end_date - start_date).days + 1) // 7 , freq='7D')\n",
    "df_sliced_week = idx.to_frame(index=False, name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns for each type of PPE\n",
    "types = ['respirators', 'surgicalMasks', 'faceShields', 'safetyGoggles', 'safetyGlasses', 'disposableBooties', 'nitrileGloves', 'gowns', 'coveralls', 'surgicalCaps', 'handSanitizer', 'disinfectingWipes', 'thermometers', 'handmadeMasks', 'printedFaceShields']\n",
    "for t in types:\n",
    "    df_sliced_week[t] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tally up binary yes's/no's for each week\n",
    "types_reqs = ['requested' + t[0].upper() + t[1:] for t in types]\n",
    "for index, row in df_sliced_week.iterrows():\n",
    "    for i in range(len(types)):\n",
    "        # all matching dates\n",
    "        total = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() >= row['date'].to_pydatetime()) & (sorted_reqs['newDateCreated'].dt.normalize() < row['date'].to_pydatetime() + timedelta(days=7))]\n",
    "        # all matching dates and item was requested is True\n",
    "        items = sorted_reqs[(sorted_reqs['newDateCreated'].dt.normalize() == row['date'].to_pydatetime()) & (sorted_reqs['newDateCreated'].dt.normalize() < row['date'].to_pydatetime() + timedelta(days=7)) & (sorted_reqs[types_reqs[i]])]\n",
    "#         print(temp)\n",
    "\n",
    "        # Normalize based on each date's total number of requests\n",
    "        if len(total.index) == 0:  # don't divide by 0\n",
    "            df_sliced_week.at[index, types[i]] = 0\n",
    "        else:\n",
    "            df_sliced_week.at[index, types[i]] = len(items.index) * 1.0 / len(total.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sliced_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "dates = [x.date() for x in list(df_sliced_week['date'])]\n",
    "dates_as_nums = [x.toordinal() for x in dates]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "for t in types:\n",
    "    coef = np.polyfit(dates_as_nums,df_sliced_week[t],1)\n",
    "    poly1d_fn = np.poly1d(coef)\n",
    "    ax.scatter(dates, df_sliced_week[t], label=t)\n",
    "    ax.plot(dates_as_nums, poly1d_fn(dates_as_nums), label=t)\n",
    "ax.legend()\n",
    "\n",
    "# ax.set_xticks(np.arange(len(dates)))\n",
    "# ax.set_xticklabels(dates)\n",
    "plt.title('Type of PPE Requested Over Time, Sliced by Week')\n",
    "plt.xlabel('Week Of')\n",
    "plt.ylabel('Normalized Number of Requests (Fraction of Requests Per Week By Type)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
